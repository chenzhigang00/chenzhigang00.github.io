1:"$Sreact.fragment"
2:I[92188,["/audio/_next/static/chunks/9b2661303dc2ecb5.js","/audio/_next/static/chunks/19952fac18a60a39.js"],"Navbar"]
3:I[19000,["/audio/_next/static/chunks/9b2661303dc2ecb5.js","/audio/_next/static/chunks/19952fac18a60a39.js"],"Hero"]
4:I[77268,["/audio/_next/static/chunks/9b2661303dc2ecb5.js","/audio/_next/static/chunks/19952fac18a60a39.js"],"NoteCard"]
9:I[16432,["/audio/_next/static/chunks/38a6e0ded54c1e98.js","/audio/_next/static/chunks/dc2bd5161e8ef372.js"],"OutletBoundary"]
a:"$Sreact.suspense"
0:{"buildId":"CatqMXwrFAXmln-2_6KKF","rsc":["$","$1","c",{"children":[["$","div",null,{"className":"min-h-screen flex flex-col","children":[["$","$L2",null,{}],["$","main",null,{"className":"flex-1","children":[["$","$L3",null,{}],["$","section",null,{"id":"notes","className":"py-24 bg-background relative z-10","children":["$","div",null,{"className":"container px-4 md:px-6 mx-auto","children":[["$","div",null,{"className":"flex flex-col items-center justify-center space-y-4 text-center mb-16","children":[["$","h2",null,{"className":"text-3xl font-bold tracking-tighter sm:text-5xl bg-clip-text text-transparent bg-gradient-to-r from-blue-400 to-purple-500","children":"Latest Research Notes"}],["$","p",null,{"className":"max-w-[900px] text-muted-foreground md:text-xl/relaxed lg:text-base/relaxed xl:text-xl/relaxed","children":"Stay updated with our latest findings, analysis, and tutorials on audio synthesis and detection."}]]}],["$","div",null,{"className":"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6","children":[["$","$L4","1",{"note":{"id":"1","title":"Understanding WaveGrad: Audio Synthesis Fundamentals","slug":"understanding-wavegrad","excerpt":"A deep dive into WaveGrad, a conditional model for waveform generation through estimating gradients of the data density. How does it compare to WaveNet?","date":"2023-10-15","readTime":"5 min","tags":["Synthesis","Generative Models","WaveGrad"]},"index":0}],["$","$L4","2",{"note":{"id":"2","title":"Detecting AI Voice Clones: Spectral Analysis Techniques","slug":"detecting-voice-clones-spectral","excerpt":"Exploring the subtle spectral artifacts left behind by modern voice cloning tools like ElevenLabs and Tortoise TTS. Can we spot the synthetic signature?","date":"2023-11-02","readTime":"8 min","tags":["Detection","Forensics","Spectral Analysis"]},"index":1}],["$","$L4","3",{"note":{"id":"3","title":"The Rise of Zero-Shot Voice Conversion","slug":"zero-shot-voice-conversion","excerpt":"Analyzing the latest advancements in zero-shot voice conversion models that require only a few seconds of reference audio. Implications for security and privacy.","date":"2023-11-20","readTime":"6 min","tags":["Voice Conversion","Security","Zero-Shot"]},"index":2}],["$","$L4","4",{"note":{"id":"4","title":"Adversarial Attacks on Deepfake Detectors","slug":"adversarial-attacks-detectors","excerpt":"Investigating how robust current deepfake detection models are against adversarial perturbations. Can we fool the detectors?","date":"2023-12-05","readTime":"7 min","tags":["Adversarial ML","Robustness","Security"]},"index":3}],["$","$L4","5",{"note":{"id":"5","title":"Watermarking Audio: A Defense Strategy","slug":"watermarking-audio-defense","excerpt":"Implementing imperceptible watermarks in audio to prove authenticity and trace the origin of synthetic content.","date":"2024-01-12","readTime":"4 min","tags":["Watermarking","Provenance","Defense"]},"index":4}],["$","$L4","6",{"note":{"id":"6","title":"Audio Deepfake Dataset Review: ASVspoof 2021","slug":"asvspoof-2021-review","excerpt":"A comprehensive review of the ASVspoof 2021 challenge dataset, focusing on logical access and physical access scenarios.","date":"2024-02-28","readTime":"9 min","tags":["Dataset","ASVspoof","Evaluation"]},"index":5}]]}]]}]}]]}],["$","footer",null,{"className":"border-t border-border bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60","children":["$","div",null,{"className":"container flex flex-col items-center justify-between gap-4 py-10 md:h-24 md:flex-row md:py-0","children":["$","div",null,{"className":"flex flex-col items-center gap-4 px-8 md:flex-row md:gap-2 md:px-0","children":["$","p",null,{"className":"text-center text-sm leading-loose text-muted-foreground md:text-left","children":["Built by"," ",["$","a",null,{"href":"#","target":"_blank","rel":"noreferrer","className":"font-medium underline underline-offset-4","children":"DeepGuard"}],". The source code is available on"," ","$L5","."]}]}]}]}]]}],["$L6","$L7"],"$L8"]}],"loading":null,"isPartial":false}
5:["$","a",null,{"href":"#","target":"_blank","rel":"noreferrer","className":"font-medium underline underline-offset-4","children":"GitHub"}]
6:["$","script","script-0",{"src":"/audio/_next/static/chunks/9b2661303dc2ecb5.js","async":true}]
7:["$","script","script-1",{"src":"/audio/_next/static/chunks/19952fac18a60a39.js","async":true}]
8:["$","$L9",null,{"children":["$","$a",null,{"name":"Next.MetadataOutlet","children":"$@b"}]}]
b:null
